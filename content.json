{"posts":[{"title":"21days muduo C++11(day01)","text":"今日目标 网络库外围模块：不可复制类，日志类 不可复制类当我们不想让一个类拥有拷贝构造能力，以及赋值能力，那么我们可以采取很多种方式。 声明为private属性，那么不可以直接拷贝构造。 但是如果定义一个public函数里面调用了这个private函数，还是可以拷贝构造的。所以private只是代表了不可以直接拷贝构造，间接拷贝构造还是可以的。 还可以只声明不定义 delete。明确说明阻止编译器生成拷贝构造函数。 以上都是针对一个类，但是大型项目中，会有很多类都有这个需求，每个类单独处理拷贝构造函数和赋值函数，比较麻烦。所以可以写一个父类NonCopyable，父类中的拷贝构造函数和赋值函数都delete掉，其他类继承NonCopyable. 代码见base/NonCopyable.h 日志类日志其实是一个大工程，自己写可能会耗费很长时间，我们这先写一个简单版。后面有时间再复现一下muduo的日志库。 写在最后在找日志库的时候，发现一个很好的日志库-spdlog，这个库可以学到一些C++技巧：头文件库和静态库的使用、锁应该如何使用、容器和容器适配器的关系、如何实现线程安全的队列等。 列在TODO list中，之后好好看一下这个库。 TODO[] spdlog库学习[] muduo日志库的完善","link":"/2023/10/26/21days-muduo-C-11-day01/"},{"title":"21days muduo C++11","text":"写在最前 作为一名服务器程序员，Linux网络编程及其重要，但是之前的我，根本就没重视这一块，现在有时间，重新梳理一下网络编程知识，学以致用，以陈硕的muduo网络库为基础，实现一个C++11版本的muduo网络库。 本博客记录21天搭建过程 网络编程基础知识1. 阻塞，非阻塞，同步，异步 其实阻塞、非阻塞，同步和异步，对于初学者来说，知道大概的意思即可，真正领会其含义，还是在实践当中。文字本身并不能准确表达出其中的区别 1.1 阻塞 非阻塞 首先明确一下，read,write,recv等函数，它们没有阻塞非阻塞一说，阻塞非阻塞是说fd。 我们拿read函数读取socket fd网络数据来举例。当调用read(fd,buf,size)的时候（就是从内核区的fd的read缓冲区读数据到用户区） fd是阻塞的，那么当fd的缓冲区没有数据，线程会挂起，直到fd的缓冲区有数据，才会继续执行（当拿到CPU时间片的情况下）。如果有数据的话，就会直接向下执行 fd是非阻塞的，那么当fd的缓冲区没有数据，线程不会挂起，它会继续执行，只不过返回结果是-1，根据返回结果-1并且errno=EGAGIN可以判断是fd没有数据 。如果有数据，返回一个&gt;0的数。 1.2 同步 异步 这组词是描述I/O把数据从内核区搬运到与用户区的方式，也可以描述业务逻辑的处理方式。 比如同样是从fd中读取数据到用户程序中。 1.2.1 同步123456char buf[1024] = {0}int size = recv(sockfd,buf,1024,0);if (size &gt; 0){ 处理数据} 调用IO接口的时候，数据是应用程序 从内核区的 TCP 接收缓冲区搬运到用户区的。 搬运数据花的时间是应用程序的时间, 都是用户态操作。也就是该线程是等搬运完数据之后再继续向下执行的。 1.2.2 异步1aio_read(&amp;aiocb) aiocb中会有一个指针指向定义的一个 aio_buf ，调用异步 IO 接口，会注册一个 sigio 信号处理函数，当操作系统搬运完数据会通过发信号 通知给应用程序，搬运数据花的时间是内核的。也就是调用完aio_read之后，该线程继续执行，不会等数据从内核区拷贝到用户区的，这个工作交给内核操作。 linux 系统中，除了aio_read,aio_write等aio_xxx函数外，其它函数都是同步函数。 1.2.3 业务逻辑中的同步异步同步异步在业务逻辑中也存在。比如一个log日志系统，会把日志写到文件中去。 日志是同步系统。当调用LogInfo(&quot;write log&quot;) 的时候，代码执行逻辑是等LogInfo把这行文字写到文件中之后才继续向下执行。 日志是异步系统。当调用LogInfo(&quot;write log&quot;) 的时候，直接继续向下执行，不会等写到文件。因为写日志的工作交给了另外一个线程来执行。这就是异步日志。 在读写 I/O 的时候，所有阻塞和非阻塞都是同步，只有使用特殊 API 的才是异步。 —-陈硕","link":"/2023/10/24/21days-muduo-C-11/"},{"title":"手把手教你写日志库C++(Day01)","text":"GitHub tinylog日志库 Day01今日任务，把日志输出到控制台。 输出结果 日志格式日志包含以下几个重要数据即可 时间 进程PID 日志级别。打印日志级别,通过查看有无ERROR日志快速定位。灵活调整日志的输出级别 日志内容 所在文件名，行号。修复问题不至于搞错对象 每条日志尽量占一行,便于分析日志 这些数据就可以满足基本要求了 日志使用对于C++来说，流式输出是最符合习惯的，也最方便，所以我们也采用这种方式LOG_INFO &lt;&lt; &quot;hello,log; 日志基本类Logger类写日志，说白了，就是把一些字符写到一个字符串当中去，然后输出出来。如果这样的话，我们就封装一个Log类，里面包含输出日志的接口，之后具体实现可以更改，接口是不变的。 重载&lt;&lt;操作符，将文件名，日志级别，时间等信息格式好提前写入buf_中 它实际上是一个临时对象,通过宏定义临时构造一个logger对象，构造的时候即将时间，进程ID等信息写入buf_,之后通过&lt;&lt;操作符写入我们的日志信息. 输出是在析构函数 极简实现查看Day01的代码 测试1234567int main(){ LOG_INFO &lt;&lt; &quot;hello,log&quot;; LOG_INFO &lt;&lt; 11111; LOG_INFO &lt;&lt; 1.000; LOG_INFO &lt;&lt; true;} 输出结果 整个代码是很简陋的，但是整体流程就是这样日志是放在一个Log中的string，然后把日期，时间，日志级别，日志内容，文件行号都append到这个string中去，在析构的时候进行打印输出这个string。这里面的流式设计也需要好好思考一下 TODO 时间精确到微妙。每条消息通过gettimeofday(2)获取当前时间.这样做不会有什么性能损失,在x86-64Linux上,gettimeofday()不是系统调用,不会陷入内核 打印线程ID,便于分析多线程程序时序,也可以检测死锁。这里可以使用thread_local，避免每次打印都系统调用，影响性能。","link":"/2023/10/30/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%86%99%E6%97%A5%E5%BF%97%E5%BA%93C-Day01/"},{"title":"手把手教你写日志库C++(Day02)","text":"Day02昨天实现的日志功能，有几个功能点是有严重问题的 存储日志的载体不能是string，因为string每次创建都是在堆上，频繁创建和销毁，很耗费性能的，所以需要用原始的栈上数组即可。 把流式操作 &lt;&lt; 拆分成LogStream类，不要和log类耦合Logger类和LogStream类封装 封装日志类LogBuffer用于缓冲输入，输入到LogStrem实现类似StringPiece类，具有char data_[]和char* cur_ LogStream类SIZE为非类型参数，直接传递值就行内含LogBuffer成员m_buffer，日志的写入都是先写入m_buffer中对字符串，整型、double类型重载了&lt;&lt;操作符bool类型，转换成’1’或’0’以字符串的形式输入 代码查看Day02的代码 测试12345678int main(){ LOG_INFO &lt;&lt; &quot;hello,log&quot;; LOG_DEBUG &lt;&lt; 5; LOG_WARN &lt;&lt; 2.000; LOG_ERROR &lt;&lt; true; return 0;}","link":"/2023/10/30/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%86%99%E6%97%A5%E5%BF%97%E5%BA%93C-Day02/"},{"title":"手把手教你写日志库C++(Day03)","text":"Day03今天把日志写到文件中去。其实原理很简单，只是把原来输出到终端变成现在的文件即可。但是其中有一些细节需要处理 实现细节 新建可写文件，模式为追加ae 滚动(rolling)。 如果文件满了，需要重建一个新的文件(默认是1GB) 如果跨天了，也会新建一个文件(每天新建一个) 刷新 每3s会刷新一下缓冲区到文件 当写日志次数超过一个阈值，也会触发刷新缓冲区 自定义文件的缓冲区为64 * 1024 （这个应该是需要根据经验来的） 关键类LogFile类LogFile日志文件类，实现日志滚动，完成日志文件的管理工作. rollfile() ：滚动文件 当日志超过m_rollsize大小时会滚动一个新的日志文件出来. get_log_file_name() ：用与滚动日志时，给日志文件取名，以滚动时间作为后缀. m_mutex ：用于append()数据时,给文件上锁. append() ：黏入日志. flush() ：冲刷缓冲. 一个典型的日志文件名serverlog.20131010-20-604.7743.logUTC时间和GMT时间是一样的，北京时间为UTC+8 fopen文件的a选项表示追加，e选项exec函数不会被继承该文件指针 File类它是最终用于操作本地文件的类. append() : 里面会调用系统函数fwrite()写入本地文件. flush() ： 冲刷缓冲. writtenBytes() ： 获取已写字节数. File类不是线程安全的，因为是无锁写入（提高效率）。通过LogFile类保证了线程安全多个线程对同一文件写入，效率可能不如单个线程，因为IO总线不能运行如果一定要多个线程写入，采用异步线程（之后会讲到） Logfile类的封装 作用： 知识点： 日志滚动条件 文件大小（例如每写满1G换下一个文件） 时间（每天零点新建一个日志文件，不论前一个文件是否写满） 一个典型的日志文件名logfile_test.20130411-115604.popo.7743.log UTC时间和GMT时间是一样的，北京时间为UTC+8 basename：basename的作用是从文件名中去除目录和后缀 多个线程对同一文件写入，效率可能不如单个线程，因为IO总线不能运行如果一定要多个线程写入，采用异步线程（之后会讲到） FILE类不是线程安全的，因为是无锁写入（提高效率）。通过LogFile类保证了线程安全startOfPeriod每次都会调整为零点，所以只有第二天才会有差异，当天时间调整后都为零点使用_r后缀的函数获取时间，保证线程安全（通过传出参数而不是返回指向一块可能被其他线程更改的缓冲区的时间）","link":"/2023/10/31/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%86%99%E6%97%A5%E5%BF%97%E5%BA%93C-Day03/"},{"title":"手把手教你写日志库C++(Day04)","text":"GitHub tinylog日志库 Day04今日任务，异步输出日志 工作逻辑 日志后端有自己的缓冲区，使用的是双缓冲区，实际实现上使用了 4 个缓冲区。缓冲区使用LogBuffer 对象(大小为4 * 1024 * 1024字节)，缓冲区使用std::unique_ptr管理，通过移动语义来实现缓冲区之间的交换，避免了缓冲区内容的复制成本。 可能同时多个线程向日志后端提交日志，因此 append 函数加锁，其逻辑如下：首先写 m_curbuffer 缓冲区，写满之后使用 m_nextbuffer 缓冲区，两个都写满时再重新分配新的缓冲区。所有写满的缓冲区都移入m_buffer_vec 中保存，等待消费者写入磁盘。当写满一个缓冲区后就立即唤醒条件变量，从而让消费者线程将缓冲区写入磁盘。 LogFile 是对写入磁盘文件的一个封装，它能在文件大小超过 rollSize 后自动写一个新的文件，这样防止单个日志文件过大。调用其 append 函数 flush 函数能够写入磁盘和刷新磁盘缓冲区，其详细设计可以参考源码。 线程函数每次在条件变量上休眠，唤醒条件有两个：(1) 生产者唤醒；(2) 超时。超时时间为 3 s，因此最长每 3 s就会将缓冲区的日志写入磁盘一次。这里注意临界区里将当前在写的缓冲区加入了 m_buffer_vec 并 swap 了 write_buffer_vec 和 m_buffer_vec，而不是将整个写入磁盘的操作也放进临界区里，提高效率。 之后调用output.append()来将日志写入磁盘，并调用output.flush()来刷新 IO 的内核缓冲区，确保日志写入磁盘中。 关键类AsyncLogging异步日志类 完成日志的异步写入工作. m_curbuffer : 指向当前接收其他线程append过来的日志的缓存. m_buffer_vec : 用于存放当前已写满或过了冲刷周期的日志缓存的指针容器. m_nextbuffer : 指向当m_curbuffer满后用于替代 - m_curbuffer的缓存. buffer_a : 备用缓存. buffer_b : 备用缓存. write_buffer_vec : 和m_buffer_vec通过交换swap()后append()到LogFile的指针容器. Mutex ：用来控制多线程的写入. Condition : 用来等待缓冲区中的数据. Thread : 使用一个线程处理缓存的交换,以及日志的写入. AsyncLogging 使用的双缓冲机制 有两个缓存容器 : m_buffer_vec 、write_buffer_vec 交替使用 . 一下我们简称为 A 和 B .A 用于接收 其他线程 append() 进来的日志.B 用于将目前已接受的缓存 写入 日志文件. 当B写完时 , clean() B , 交换A，B，如此往复. 下图来源于网络，侵删 实际上还有几个备用缓存,这里没有加上去,以便于理解程序; 备用缓存主要是为了减少反复new 操作带来的系统开销， 增加备用缓存增加备用缓存优化上面程序，上面程序一共在两个地方执行了new操作.1.m_curbuffer 填满时，需要把它填进容器的时候.2.到时间了需要把m_curbuffer里面的内容写入本地文件时,会把它当前的内容移出来，这时候需要new一个新缓存来给m_curbuffer. 于是我们准备一个m_nextbuffer来做m_curbuffer的备用缓存.同时在线程中增加两个backupBuffer 给m_nextbuffer 当备用缓存；当日志量大到不够用的时候, 再考虑用new 操作来动态添加缓存。下图来源于网络，侵删 25的含义：25个缓冲，每个4MB，共100MB。也就是说，上次处理周期到本次，已经堆积了超过100MB数据待处理。假设磁盘的写速度100MB/S，要堆积100MB有2种极端情况：1）1S内产生200MB数据；2）25秒内，平均每秒产生104MB数据； 不论哪种情况，都是要超过磁盘的处理速度。而实际应用中，只有产生数据速度不到磁盘写速度的1/10，应用程序性能才不会受到明显影响。 异步模型1：双缓冲技术准备两块buffer：A和B,前端负责往buffer A填数据(日志消息)，后端负责将buffer B的数据写入文件buffer A写满后，交换A和B,让后端将buffer A的数据写入文件，前端则往buffer B种填入新的日志消息为了及时将日志消息写入文件，即便buffer A未满，也会每3秒执行一次叫交换写入操作 后端线程函数threadFunc，会构建1个LogFile对象，用于控制log文件创建、写日志数据，创建2个空闲缓冲区buffer1、buffer2，和一个待写缓冲队列write_buffer_vec，分别用于替换当前缓冲currentBuffer_、空闲缓冲nextBuffer_、已满缓冲队列buffers_，避免在写文件过程中，锁住缓冲和队列，导致前端无法写数据到后端缓冲。threadFunc中，提供了一个loop，基本流程是这样的：1）每次当已满缓冲队列中有数据时，或者即使没有数据但3秒超时，就将当前缓冲加入到已满缓冲队列（即使当前缓冲没满），将buffer1移动给当前缓冲，buffer2移动给空闲缓冲（如果空闲缓冲已移动的话）。2）然后，再交换已满缓冲队列和待写缓冲队列，这样已满缓冲队列就为空，待写缓冲队列就有数据了。3）接着，将待写缓冲队列的所有缓冲通过LogFile对象，写入log文件。4）此时，待写缓冲队列中的缓冲，已经全部写到LogFile指定的文件中（也可能在内核缓冲中），擦除多余缓冲，只用保留两个，归还给buffer1和buffer2。5）此时，待写缓冲队列中的缓冲没有任何用处，直接clear即可。6）将内核高速缓存中的数据flush到磁盘，防止意外情况造成数据丢失。 异常处理：当已满缓冲队列中的数据堆积（默认缓冲数超过25），就会丢弃多余缓冲，只保留最开始2个。为什么保留2个？个人觉得2个~16个都是可以的，不过，为了有效减轻log导致的负担，丢弃多余的也未尝不可。 优点 ： 新建的日志不必等待磁盘操作，也避免了每条新日志都触发日志线程，而是将多条日志拼程一个大的buffer 传送给日志线程写入文件. 相当于批处理， 减少线程唤醒频率 ，降低开销。另外 ，为了及时将 日志消息写入文件， 即是 buffer A 中还没有push进来日志 也会每三秒 执行一次上述的写入操作.","link":"/2023/11/30/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%86%99%E6%97%A5%E5%BF%97%E5%BA%93C-Day04/"},{"title":"手把手教你写异步日志库C++","text":"GitHub tinylog日志库 前言开发程序，日志是必不可少的。因为程序一旦发布或部署，就不允许直接通过调试来排查问题了，这时候日志成为观察程序运行情况的重要工具。作为一个最基础的组件，涉及到一些高性能编程的设计原则，以及Linux内核原理。为了熟悉Linux编程以及网络编程，从头开发一款小而精的日志库，作为一个学习练手项目，十分合适。首先在一个服务器系统中写日志，就是把一些数据写到终端或者文件中去。为了梳理整个流程，本教程类似《30天制作操作系统》，分成4天，循序渐进的每一天实现一小部分，完全符合开发流程。 Day01:日志写到终端。我们先把日志写到终端，走一遍整个流程，之后我们再一步步优化。Day01博客Day02: 功能拆分，降低耦合。Day02博客Day03: 把日志写到文件中。Day03博客Day04: 异步写日志。Day04博客 日志分类同步日志同步日志是指产生日志的同时就将其写入至文件中，这种方式优点是设计简单、能够及时的将日志输出到文件中，缺点是会频繁的触发 IO 操作，且对写日志的线程阻塞。在客户端程序中，这种方式很常见，写入几条日志的时间相比于用户的反应时间来说可以忽略不计，用户很难察觉这点性能损失。 异步日志对于服务端程序而言，使用同步写日志的方式会影响性能，服务器线程阻塞时间越长，其为客户端提供服务的时间就越短，同时为多个客户端提供服务的能力也越差。现代计算机的 CPU 一般都是具有多个核心的，因此服务端程序常采用多线程程序来尽量发挥每一个核心的能力，异步日志为了减少写日志对线程的阻塞，采用一个单独的线程来向磁盘写入日志，其它线程只是产生日志并将其交给写磁盘线程。 异步日志是一个典型的生产者消费者模型，分为日志前端和日志后端。前端就是生产者，也就是产生日志的一方，后端是日志的消费者，负责将日志写入磁盘，通常使用一个单独的线程来完成。本教程实现了一个简单的异步日志系统，下面介绍这个日志系统的设计实现。 日志目标 默认输出到控制台 支持配置日志保存路径和文件 日志滚动 支持设置日志最大保存时长，自动清理过期日志 支持 DEBUG、INFO、WARN、ERROR 四种级别日志输出 流式风格LOG_INFO &lt;&lt; “Lily is “ &lt;&lt; 8 &lt;&lt; “ years old.”; 日志信息丰富，包括时间、线程号、UUID、日志级别、文件、行号、函数名 异步输出到文件 日志级别 DEBUG 指出细粒度信息事件对调试应用程序是非常有帮助的。（开发过程中使用） INFO 表明消息在粗粒度级别上突出强调应用程序的运行过程。 WARN 系统能正常运行，但可能会出现潜在错误的情形。 ERROR 指出虽然发生错误事件，但仍然不影响系统的继续运行。 从上往下级别增大 实现步骤 先实现一个同步日志，输出到控制台，也就是说 LOG_INFO &lt;&lt; &quot;hello&quot; &lt;&lt; myname; 这时候在终端显示的是 “hello,lk” 把日志输出到文件中去 异步日志，前后端分离 优化 benchmark 日志模型多生产者-单消费者采用双缓冲区（double buffering）交互技术。减少锁的竞争。基本思想是准备2部分buffer：A和B，前端（front end）线程往buffer A填入数据（日志消息），后端（back end）线程负责将buffer B写入日志文件。当A写满时，交换A和B。如此往复。 实现时，在后端设置一个已满缓冲队列（Buffer1~n，2&lt;=n&lt;=16），用于缓存一个周期内临时要写的日志消息。 这样做到好处在于：1）线程安全；2）非阻塞。 这样，2个buffer在前端写日志时，不必等待磁盘文件操作，也避免每写一条日志消息都触发后端线程。 异常处理：当一个周期内，产生过多Buffer入队列，当超过队列元素上限数量值25时，直接丢弃多余部分，并记录。 日志前端 每个线程都有自己的前端 尽量低延迟，低CPU开销，无阻塞。 提供供应用程序使用的接口，生成日志消息，Logging.{h.cpp},在类析构的时候写入消息、 日志后端 整个程序共用一个后端，难点在于将日志数据从多个前端高效地传输到后端 足够大地吞吐量，占用较少资源 把日志消息写到目的地,LogFile.{h.cpp},，封装了Log文件的打开、写入并在类析构的时候关闭文件 多线程异步模型，AsyncLogging.{h.cpp},负责启动一个log线程，专门用来将log写入LogFile 输入的stream模型，LogStream.{h.cpp},用来格式化输出，重载了&lt;&lt;运算符 高性能日志库需求只有日志库足够高效，程序员才敢在代码中输出足够多的诊断信息，减小运维难度，提升效率.它体现在： 每秒几千万条日志没有明显的性能损失 能应对一个进程产生大量日志数据的场景，如1GB/min。 不阻塞正常的执行流程 在多线程程序中，不造成争用为了实现性能指标，日志设计中还需实现的几点优化： 时间戳字符串中的日期和时间两部分缓存下来,一秒之内的多条日志只需格式化微妙即可 日志消息 的前四段是定长的,可避免运行时字串长度的计算 线程id，预先格式化字符串 原文件名部分通过编译期计算来获得,避免运行期strrchr()的开销","link":"/2023/10/30/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%86%99%E6%97%A5%E5%BF%97%E5%BA%93C/"},{"title":"火焰图","text":"前言想到火焰图，就应该能回答下面几个问题 是什么 什么时候用它 怎么看火焰图 自己使用的案例 优秀博客《C++性能优化指南》 如何读懂火焰图？– 阮一峰 是什么 当程序发现CPU一直满载的时候，说明程序遇到性能瓶颈了，这时候可以使用perf工具进行查看，是哪些热点函数导致CPU满载。但是Perf不是特别直观，这时候就用火焰图，把检测数据直观的表现出来 Perf原理每隔一段时间，就在CPU上（每个核）产生一个终端，在中断上看当前是哪个pid,哪个函数，然后给pid和函数加一个统计值。最后就知道CPU有百分之几的时间在某个pid上或者某个函数上。默认on cpu ,可选off CPU测试IO阻塞或者锁 什么时间用onCPU什么时间用offCPU，取决于当前的瓶颈是什么？如果CPU占用快到100%了那就用oncpu，如果CPU占用不高，那就用offCPU。如果无法确认，那就用压测工具把CPU压到100%，使用On CPU。如果不管怎么压都不到100% ，那就用off CPU 局限性 调用栈太深的时候，可能调用栈只能显示前面一部分 有些匿名函数显示不了 场景： 寻找热点函数，定位性能瓶颈 分析CPU分支预测 分析火焰图分析火焰图基本原则：从栈顶开始，往栈底分析拿到一张火焰图，重点是看方块的宽度。宽度代表抽样出现的次数，进而说明耗时。而重点应该是顶部的一些平顶山。 排查性能问题线上CPU很高的时候，怎么处理？排查思路 top查看占用CPU最高的进程pid 然后top -Hp pid 查进程中的线程 服务器性能测试常见指标测试指标：1. QPS 2. 响应时间压测：1. 并发数 2. 请求个数 分析：1. QPS 红蓝差有个红蓝差火焰图：比如你定位到了瓶颈，然后进行了修改，这时候又使用了火焰图进行了分析，可以把这次和修改前的火焰图进行比较，生成了红蓝差火焰图，更加直观。 项目中更直观的性能分析比火焰图更直观的用调用图 工具gprof2dot，它可以生成调用图，颜色深浅表示占用CPU时间，蓝色最少，红色最多。 安装123456789采集工具apt install linux-perf 生成调用图数据工具pip3 install gprof2dot 绘图工具apt install graphviz修改 /etc/sysctl.conf 添加kernel.perf_event_paranoid =-1执行sysctl -p否则非root 账号无法使用perf 命令采集性能数据 颜色深浅代表消耗CPU占比，蓝色最少，红色最多第一个数字代表本函数以及本函数调用的函数消耗CPU总和第二个数字代表本函数消耗CPU占比。本图例说明AddShow 函数本身只消耗了0.03%CPU，但是调用的函数消耗CPU总和为52.37%，需要顺着调用往下找。主要方法就是找到调用图中明显的绿线，或者刺眼的绿色方块 使用12perf record -F 99 -g-p 72064 # 采样 pid 为 72064 的进程采样频率 99HZperfscript|c++filt|gprof2dot -fperf|dot-Tpng-o output.png// 采样结果生成调用图 实战场景在项目中，有一次QA同学发现版本包导致内存占用很高（还是CPU忘记了，按理来说写日志不消耗CPU呀），perf + gperf2dot分析，发现调用颜色最深的是打印Debug日志，线上环境是不开Debug的，所以关掉Debug再次测试，没啥问题就OK了。","link":"/2023/12/02/%E7%81%AB%E7%84%B0%E5%9B%BE/"},{"title":"红黑树+Hash+B+树 备忘录","text":"红黑树前言红黑树基础知识，这里就不再赘述了，详情可以看红黑树（图解+秒懂+史上最全），写的非常好，respect！ BST(可能退化成单链表) –&gt; AVL(只适合查询，不适合频繁插入删除，因为每次增删操作都会旋转) –&gt; RBTree(牺牲严格的平衡条件，换区少量的旋转操作，不超过3次就可以解决不平衡问题)，最坏情况都是O(logN)完成查找 红黑树思考 红黑树都用在什么地方主要是用红黑树的插入删除查找 时间复杂度是 O(logN).所以需要快速查找的地方都可能用到。这里的竞争者就是哈希表.红黑树多出来一个优点： 中序遍历是有顺序的 epoll Map,Set(C++) 这里用到了顺序这个特性 定时器（有待补充） 补充强查找数据结构 哈希表 跳表 B/B+树 RBTree 定义下红黑树的结构，不需要实现具体操作 123456789101112131415typedef int KEY_TYPE;typedef struct _rbtree_node { unsigned char color; struct _rbtree_node *right; struct _rbtree_node *left; struct _rbtree_node *parent; KEY_TYPE key; void *value;} rbtree_node;typedef struct _rbtree { rbtree_node *root; rbtree_node *nil;} rbtree; 红黑树对比哈希表的优势 红黑树 哈希表 有序 无需 最差情况Log(N) 最差情况O(N) 有多少元素就分配多少内存 预先估计大小，rehash比较消耗性能 B/B+ 树漫画：什么是B+树？B树和B+树详解 M叉树，用来做数据库的索引B 树： 中间节点包含数据B+树：只有叶子节点包含数据 Hash 手写一个简易hash表1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;list&gt;// 定义哈希表的节点template&lt;typename K, typename V&gt;struct HashNode { K key; V value; HashNode(const K&amp; k, const V&amp; v) : key(k), value(v) {}};// 哈希表类定义template&lt;typename K, typename V, typename Hash = std::hash&lt;K&gt;&gt;class HashMap {public: explicit HashMap(int size = 100) : size_(size), count_(0), table_(size) {} // 向哈希表中插入键值对 void insert(const K&amp; key, const V&amp; value) { int index = hashFunction(key); for (auto it = table_[index].begin(); it != table_[index].end(); ++it) { if ((*it).key == key) { (*it).value = value; // 如果键已经存在，则更新其对应的值 return; } } table_[index].push_back(HashNode&lt;K, V&gt;(key, value)); count_++; } // 根据键查找对应的值 bool find(const K&amp; key, V&amp; value) { int index = hashFunction(key); for (auto it = table_[index].begin(); it != table_[index].end(); ++it) { if ((*it).key == key) { value = (*it).value; return true; // 找到键，并将对应的值赋给参数value } } return false; // 未找到键 } // 从哈希表中删除指定的键值对 void erase(const K&amp; key) { int index = hashFunction(key); for (auto it = table_[index].begin(); it != table_[index].end(); ++it) { if ((*it).key == key) { table_[index].erase(it); // 删除节点 count_--; return; } } }private: std::vector&lt;std::list&lt;HashNode&lt;K, V&gt;&gt;&gt; table_; // 哈希表存储数据的数组，每个元素是一个链表 int size_; // 哈希表的大小（桶数量） int count_; // 当前存储在哈希表中的键值对数量 Hash hashFunction; // 哈希函数对象 // 根据键计算哈希值，并映射到合适的桶索引 int hashFunction(const K&amp; key) { return hashFunction(key) % size_; }}; 新认识上面写的hash表和STL的中有一个最大的不同，就是每个桶之间是没有联系的以前以为STL中的unordered_map的哈希表是这样的但是这样的话，遍历整个map,时间复杂度大概是O(N+K),K是桶的个数，而K一般都比较大。所以，为了遍历时间复杂度为O(N),真正的结构是具体分析看 拉链法的 unordered_map 和你想象中的不一样新建一个unordered_map,成员包括 数组buckets，数组成员是指向链表节点的指针 _M_before_begin哨兵节点，可以理解为一个虚拟链表节点当插入一个节点的时候 在bucket有值的时候，都是通过前一个指针和头插法插入到对应的 bucket 内。 如果 bucket 没有值，就会把哨兵节点切换到新的 bucket 中。注意插入节点都是使用 头插法 小优化：当每个桶中的链表长度超过一个阈值（比如256）的时候，将链表转化为红黑树或者堆 负载因子 &gt; 1,需要rehash；小于0.1，也需要rehash。在这之间，就会拉链法或者开放寻址法处理hash冲突 布隆过滤器 什么场景下用布隆过滤器对于红黑树，hash表，都是存储了key + value。如果我们只想知道key存不存在，为了节省内存，就不需要存value。 数据库查找某个文件在不在 垃圾邮件过滤算法 构成bitmap + 多个hash函数 怎么确定bitmap大小和hash函数的个数，才能使假阳率最低？有数学证明，输入要保存的数据个数，还有期望的假阳率，就会给出最佳bitmap大小和hash个数 为什么很多hash函数个数是31？因为数学证明，在bitmap大小确定的情况下，31个哈希函数使得假阳率最低。","link":"/2023/11/27/%E7%BA%A2%E9%BB%91%E6%A0%91+Hash+B%E6%A0%91/"}],"tags":[{"name":"muduo,C++","slug":"muduo-C","link":"/tags/muduo-C/"},{"name":"log","slug":"log","link":"/tags/log/"},{"name":"火焰图","slug":"火焰图","link":"/tags/%E7%81%AB%E7%84%B0%E5%9B%BE/"},{"name":"基础知识","slug":"基础知识","link":"/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"perf","slug":"perf","link":"/tags/perf/"}],"categories":[{"name":"Linux编程","slug":"Linux编程","link":"/categories/Linux%E7%BC%96%E7%A8%8B/"},{"name":"性能优化","slug":"性能优化","link":"/categories/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"name":"基础知识","slug":"基础知识","link":"/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"pages":[]}